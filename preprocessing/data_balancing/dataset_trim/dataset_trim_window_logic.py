import pandas as pd
from sklearn.model_selection import train_test_split
from imblearn.under_sampling import RandomUnderSampler
from PySide6.QtWidgets import QMessageBox, QInputDialog, QFileDialog
import numpy as np
import os

class DatasetTrimLogic:
    def __init__(self, parent=None):
        
        self.dataset_filename = ''
        self.X = None
        self.y = None
        self.X_train = None
        self.y_train = None
        self.X_test = None
        self.y_test = None
        self.X_resampled = None
        self.y_resampled = None
        self.feature_cols = []
        self.target_col = ''
        self.parent_widget = parent


    def load_dataset(self, ui):        
        file_dialog = QFileDialog()
        file_dialog.setDirectory('./dataset')
        file_name, _ = file_dialog.getOpenFileName(ui, "–í—ã–±–æ—Ä –¥–∞—Ç–∞—Å–µ—Ç–∞", "", "CSV Files (*.csv)")
        
        if file_name:
            df = pd.read_csv(file_name)
            self.dataset_filename = file_name
            
            numeric_columns = df.select_dtypes(include=['number']).columns.tolist()
            
            if not numeric_columns:
                QMessageBox.critical(ui, "–û—à–∏–±–∫–∞", "–í –¥–∞—Ç–∞—Å–µ—Ç–µ –Ω–µ—Ç —á–∏—Å–ª–æ–≤—ã—Ö —Å—Ç–æ–ª–±—Ü–æ–≤.")
                return
                
            item, ok = QInputDialog.getItem(
                ui, 
                "–í—ã–±–æ—Ä —Ü–µ–ª–µ–≤–æ–π –ø–µ—Ä–µ–º–µ–Ω–Ω–æ–π", 
                "–í—ã–±–µ—Ä–∏—Ç–µ —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é:", 
                numeric_columns, 
                editable=False
            )
            
            if ok and item:
                target_col = item
                feature_cols = list(set(numeric_columns) - {item})
                self.feature_cols = feature_cols
                self.target_col = target_col
                
                self.X = df[feature_cols].values
                self.y = df[target_col].values
                
                self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(
                    self.X, self.y, test_size=0.2, random_state=42
                )
                
                # === üîß –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –≤—ã–≤–æ–¥ –∫–ª–∞—Å—Å–æ–≤ –¥–æ 15 ===
                class_counts = pd.Series(self.y_train).value_counts()
                total_classes = len(class_counts)
                
                if total_classes > 15:
                    top_15 = class_counts.iloc[:15]
                    remaining = total_classes - 15
                    stats_text = f"{top_15.to_string()}\n... –∏ –µ—â—ë {remaining} –∫–ª–∞—Å—Å–æ–≤"
                else:
                    stats_text = class_counts.to_string()
                
                ui.before_label.setText(f"–î–æ –±–∞–ª–∞–Ω—Å–∏—Ä–æ–≤–∫–∏:\n{stats_text}")
                ui.after_label.clear()
                ui.file_name_label.setText(f"–î–∞—Ç–∞—Å–µ—Ç –∑–∞–≥—Ä—É–∂–µ–Ω: {os.path.basename(file_name)}")
                
            else:
                QMessageBox.warning(ui, "–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ", "–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –≤—ã–±—Ä–∞—Ç—å —Ü–µ–ª–µ–≤—É—é –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é!")

                
    def trim_dataset(self, target_samples):
        if self.X_train is None or self.y_train is None:
            raise Exception("–°–Ω–∞—á–∞–ª–∞ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞—Ç–∞—Å–µ—Ç.")

        current_samples = pd.Series(self.y_train).value_counts()
        unique_classes = len(current_samples)
        
        for i in range(unique_classes):
            class_value = current_samples.index[i]
            if target_samples > current_samples.loc[class_value]:
                raise Exception(f"({target_samples}) –ø—Ä–µ–≤—ã—à–∞–µ—Ç –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ {class_value}. –∑–Ω–∞—á–µ–Ω–∏—è: {current_samples}")

        sampling_strategy = {value: target_samples for value in current_samples.index}
        
        sampler = RandomUnderSampler(sampling_strategy=sampling_strategy, random_state=42)
        X_trimmed, y_trimmed = sampler.fit_resample(self.X_train, self.y_train)
        
        y_trimmed = np.round(y_trimmed).astype(int)
        X_trimmed = np.round(X_trimmed).astype(int)

        after_stats = pd.Series(y_trimmed).value_counts().to_string()
    
        # –û–±–Ω–æ–≤–ª—è–µ–º –∞—Ç—Ä–∏–±—É—Ç—ã –∫–ª–∞—Å—Å–∞ –Ω–æ–≤—ã–º –Ω–∞–±–æ—Ä–æ–º –¥–∞–Ω–Ω—ã—Ö
        self.X_resampled = X_trimmed
        self.y_resampled = y_trimmed
        
        return X_trimmed, y_trimmed
    
    def save_trimmed_dataset(self, target_samples):
        if not hasattr(self, 'X_resampled'):
            raise Exception('–û–±—Ä–µ–∑–∞–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç –µ—â—ë –Ω–µ —Å–æ–∑–¥–∞–Ω.')
        
        try:
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã—Ö –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            required_attrs = ['feature_cols', 'target_col', 'dataset_filename']
            missing_attrs = [attr for attr in required_attrs if not hasattr(self, attr)]
            if missing_attrs:
                raise AttributeError(f"–ê—Ç—Ä–∏–±—É—Ç—ã {missing_attrs} –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç.")
            
            # –ü–µ—á–∞—Ç—å —Ç–µ–∫—É—â–∏—Ö –∑–Ω–∞—á–µ–Ω–∏–π –∞—Ç—Ä–∏–±—É—Ç–æ–≤
            print(f"–ó–Ω–∞—á–µ–Ω–∏—è –∞—Ç—Ä–∏–±—É—Ç–æ–≤ –ø–µ—Ä–µ–¥ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –¥–∞—Ç–∞—Å–µ—Ç–∞:")
            print(f"Feature cols: {self.feature_cols}")
            print(f"Target col: {self.target_col}")
            print(f"Dataset filename: {self.dataset_filename}")
            
            # –ü—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω—É—é –ø—Ä–æ—Ü–µ–¥—É—Ä—É
            filename_base = os.path.basename(self.dataset_filename).split('.')[0]
            new_filename = f"{filename_base}_trimmed_{target_samples}.csv"
            
            # –§–æ—Ä–º–∏—Ä—É–µ–º –¥–∞—Ç–∞—Ñ—Ä–µ–π–º —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω–æ–π —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
            data_dict = {}
            for idx, column in enumerate(self.feature_cols):
                data_dict[column] = self.X_resampled[:, idx]
            data_dict[self.target_col] = self.y_resampled
            
            trimmed_df = pd.DataFrame(data_dict)
            
            directory = './dataset'
            full_path = os.path.join(directory, new_filename)
            
            trimmed_df.to_csv(full_path, index=False)
            
            print(f'–î–∞—Ç–∞—Å–µ—Ç —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {full_path}')
        except AttributeError as ae:
            print(f'–û—à–∏–±–∫–∞: {ae}')
        except FileNotFoundError:
            print("–ö–∞—Ç–∞–ª–æ–≥ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –¥–∞—Ç–∞—Å–µ—Ç–æ–≤ –Ω–µ –Ω–∞–π–¥–µ–Ω.")
        except IOError:
            print("–û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ —Ñ–∞–π–ª–∞.")
        except Exception as e:
            print(f'–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏: {e}')
           
