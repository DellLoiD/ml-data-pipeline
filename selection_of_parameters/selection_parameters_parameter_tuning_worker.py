# selection_parameters_parameter_tuning_worker.py
import logging
from PySide6.QtCore import Signal, QThread
import pandas as pd
from sklearn.model_selection import train_test_split, RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score
from sklearn.preprocessing import LabelEncoder
from .selection_of_parameters_logic import get_random_grid, get_random_search_params

logger = logging.getLogger(__name__)


class ParameterTuningWorker(QThread):
    progress_updated = Signal(float, int, int)
    tuning_completed = Signal(object, dict, float, str)
    error_occurred = Signal(str)

    def __init__(self, parent=None, dataset_path=None, target_variable=None, model_type=""):
        super().__init__(parent)
        self.dataset_path = dataset_path
        self.target_variable = target_variable
        self.model_type = model_type
        self._is_running = False

    def run(self):
        if self._is_running:
            logger.warning("ParameterTuningWorker —É–∂–µ –∑–∞–ø—É—â–µ–Ω ‚Äî –ø—Ä–æ–ø—É—Å–∫.")
            return
        self._is_running = True

        try:
            logger.info("=== –ó–∞–ø—É—Å–∫ –ø–æ–¥–±–æ—Ä–∞ ===")

            # === 1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö ===
            df = pd.read_csv(self.dataset_path)
            if self.target_variable not in df.columns:
                raise ValueError(f"–¶–µ–ª–µ–≤–∞—è –ø–µ—Ä–µ–º–µ–Ω–Ω–∞—è '{self.target_variable}' –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")

            X = df.drop(columns=[self.target_variable])
            y = df[self.target_variable].copy()

            # –ö–æ–¥–∏—Ä–æ–≤–∞–Ω–∏–µ —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –º–µ—Ç–æ–∫
            if y.dtype == 'object':
                y = LabelEncoder().fit_transform(y)
            n_classes = len(pd.unique(y))

            # === 2. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –∏–∑ logic.py (–µ–¥–∏–Ω—Å—Ç–≤–µ–Ω–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫!) ===
            params = get_random_search_params()
            grid = get_random_grid()
            hyperparams = grid.get(self.model_type)

            if not hyperparams:
                raise ValueError(f"–ù–µ—Ç –≥–∏–ø–µ—Ä–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –¥–ª—è: {self.model_type}")

            # === 3. –°–æ–∑–¥–∞–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ë–ï–ó –∂—ë—Å—Ç–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ ===
            model_classes = {
                'RandomForest': RandomForestClassifier,
                'GradientBoosting': GradientBoostingClassifier,
                'LogisticRegression': LogisticRegression
            }
            model_cls = model_classes.get(self.model_type)
            if not model_cls:
                raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –º–æ–¥–µ–ª—å: {self.model_type}")
            estimator = model_cls()  # –í—Å–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã ‚Äî –∏–∑ scoring, refit –∏ —Ç.–¥.

            # === üîπ –û–ü–†–ï–î–ï–õ–ï–ù–ò–ï –¢–ò–ü–ê –ó–ê–î–ê–ß–ò: –±–∏–Ω–∞—Ä–Ω–∞—è vs –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–∞—è === #
            # –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∏–∑ logic.py
            scoring = params['scoring']  # dict: {'accuracy': 'accuracy', 'roc_auc': 'roc_auc'}
            refit = params['refit']      # –Ω–∞–ø—Ä–∏–º–µ—Ä, 'roc_auc' ‚Äî —ç—Ç–æ –ö–õ–Æ–ß –≤ —Å–ª–æ–≤–∞—Ä–µ scoring
            multi_class = params.get('multi_class', 'ovr')  # 'ovr' –∏–ª–∏ 'ovo'

            # üî∏ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –±–∏–Ω–∞—Ä–Ω–æ–π –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏–∏ (n_classes == 2):
            #   - scoring: 'roc_auc', 'f1', 'accuracy'
            #   - refit: —Å–æ–≤–ø–∞–¥–∞–µ—Ç —Å–æ scoring (–∫–ª—é—á!)
            #   - predict_proba: –±–µ—Ä–µ–º [:, 1]
            #   - roc_auc_score: –±–µ–∑ multi_class
            #
            # üîπ –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –¥–ª—è –º–Ω–æ–≥–æ–∫–ª–∞—Å—Å–æ–≤–æ–π (n_classes > 2):
            #   - scoring: {'roc_auc': 'roc_auc_ovr'} ‚Äî –∑–Ω–∞—á–µ–Ω–∏–µ (scorer) –º–µ–Ω—è–µ—Ç—Å—è, –∫–ª—é—á –æ—Å—Ç–∞—ë—Ç—Å—è
            #   - refit: 'roc_auc' ‚Äî —Å—Å—ã–ª–∞–µ—Ç—Å—è –Ω–∞ –∫–ª—é—á, –Ω–µ –Ω–∞ scorer!
            #   - multi_class: 'ovr' –∏–ª–∏ 'ovo' ‚Äî –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –≤ roc_auc_score
            #   - average: 'weighted' –∏–ª–∏ 'macro' –≤ –º–µ—Ç—Ä–∏–∫–∞—Ö

            # --- –ò–°–ü–†–ê–í–õ–ï–ù–ò–ï –û–®–ò–ë–ö–ò: –ú–µ–Ω—è–µ–º scorer, –Ω–æ –Ω–µ –∫–ª—é—á –∏ –Ω–µ refit! ---
            if n_classes > 2 and isinstance(scoring, dict):
                # –û–±–Ω–æ–≤–ª—è–µ–º –∑–Ω–∞—á–µ–Ω–∏—è (scorers), –Ω–æ –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–ª—é—á–∏ –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π
                scoring = {
                    name: (
                        f'roc_auc_{multi_class}' if name == 'roc_auc' else metric
                    )
                    for name, metric in scoring.items()
                }
                # –í–ê–ñ–ù–û: refit –æ—Å—Ç–∞—ë—Ç—Å—è –∫–ª—é—á–æ–º, –Ω–∞–ø—Ä–∏–º–µ—Ä 'roc_auc', –∫–æ—Ç–æ—Ä—ã–π —É–∫–∞–∑—ã–≤–∞–µ—Ç –Ω–∞ –æ–±–Ω–æ–≤–ª—ë–Ω–Ω—ã–π scorer
                # –ù–ï –ú–ï–ù–Ø–ï–ú refit –Ω–∞ 'roc_auc_ovr' ‚Äî —ç—Ç–æ –ù–ï –∫–ª—é—á –≤ —Å–ª–æ–≤–∞—Ä–µ!

            # === 4. –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –ø–æ–∏—Å–∫–∞ ===
            n_iter = params['n_iter']
            cv = params['cv']
            verbose = params['verbose']
            n_jobs = params['n_jobs']
            random_state = params['random_state']
            test_size = params['test_size']

            # === 5. –†–∞–∑–¥–µ–ª–µ–Ω–∏–µ ===
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=random_state, stratify=y
            )

            # === 6. –ü–æ–∏—Å–∫ ===
            search = RandomizedSearchCV(
                estimator=estimator,
                param_distributions=hyperparams,
                n_iter=n_iter,
                cv=cv,
                scoring=scoring,
                refit=refit,  # ‚úÖ 'roc_auc' ‚Äî —ç—Ç–æ –∫–ª—é—á, —É–∫–∞–∑—ã–≤–∞—é—â–∏–π –Ω–∞ scorer 'roc_auc_ovr'
                random_state=random_state,
                verbose=verbose,
                n_jobs=n_jobs
            )

            # === 7. –û–±—É—á–µ–Ω–∏–µ ===
            self.progress_updated.emit(0.0, 0, n_iter)
            search.fit(X_train, y_train)
            self.progress_updated.emit(100.0, n_iter, n_iter)

            # === 8. –û—Ü–µ–Ω–∫–∞ ===
            model = search.best_estimator_
            pred = model.predict(X_test)
            acc = accuracy_score(y_test, pred)
            f1 = f1_score(y_test, pred, average='macro', zero_division=0)

            roc_auc = 0.0
            if hasattr(model, "predict_proba"):
                if n_classes == 2:
                    proba = model.predict_proba(X_test)[:, 1]
                    roc_auc = roc_auc_score(y_test, proba)
                else:
                    proba = model.predict_proba(X_test)
                    roc_auc = roc_auc_score(
                        y_test, proba,
                        multi_class=multi_class,
                        average='weighted'
                    )

            metrics = (
                f"Accuracy: {acc:.4f}\n"
                f"F1 Macro: {f1:.4f}\n"
                f"Precision Macro: {precision_score(y_test, pred, average='macro', zero_division=0):.4f}\n"
                f"Recall Macro: {recall_score(y_test, pred, average='macro', zero_division=0):.4f}\n"
                f"ROC AUC: {roc_auc:.4f}"
            )

            self.tuning_completed.emit(model, search.best_params_, acc, metrics)

        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞: {e}")
            self.error_occurred.emit(str(e))
        finally:
            self._is_running = False
